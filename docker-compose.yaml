name: log-beaver

x-airflow-common: &airflow-common
  image: apache/airflow:3.1.3-python3.12
  env_file:
    - .env
  environment: &airflow-common-env
    AIRFLOW__CORE__EXECUTOR: LocalExecutor
    AIRFLOW__CORE__LOAD_EXAMPLES: "false"
    AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW_FERNET_KEY:-PLEASE_SET_AIRFLOW_FERNET_KEY}
    AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW_SECRET_KEY:-PLEASE_SET_AIRFLOW_SECRET}
    AIRFLOW__API__AUTH_BACKENDS: airflow.api.auth.backend.default
    AIRFLOW__INTERNAL_API__BASE_URL: http://airflow-webserver:8080
    AIRFLOW__INTERNAL_API__AUTH_BACKENDS: airflow.api.auth.backend.default
    AIRFLOW__LOGGING__LOGGING_LEVEL: INFO
    AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK: "true"
    PIP_ADDITIONAL_REQUIREMENTS: ${PIP_ADDITIONAL_REQUIREMENTS:-"dbt-clickhouse==1.7.0 astronomer-cosmos==1.11.2"}
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:${AIRFLOW_DB_PASSWORD:-airflow}@airflow-db:5432/airflow
  volumes:
    - ./airflow/dags:/opt/airflow/dags
    - ./airflow/logs:/opt/airflow/logs
    - ./airflow/plugins:/opt/airflow/plugins
    - ./dbt:/opt/airflow/dbt
  user: "${AIRFLOW_UID:-50000}:0"
  depends_on:
    airflow-db:
      condition: service_healthy
  networks:
    - log-beaver

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.9.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    volumes:
      - zookeeper-data:/var/lib/zookeeper/data
      - zookeeper-log:/var/lib/zookeeper/log
    healthcheck:
      test: ["CMD", "bash", "-c", "echo ruok | nc -w 2 localhost 2181"]
      interval: 10s
      timeout: 5s
      retries: 10
    networks:
      - log-beaver

  kafka:
    image: confluentinc/cp-kafka:7.9.0
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9093:9093"
    environment:
      KAFKA_BROKER_ID: ${KAFKA_BROKER_ID:-1}
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://${KAFKA_ADVERTISED_HOST:-localhost}:9093
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,PLAINTEXT_HOST://0.0.0.0:9093
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_HEAP_OPTS: ${KAFKA_HEAP_OPTS:-"-Xms512M -Xmx2G"}
      KAFKA_JMX_PORT: 9999
      KAFKA_JMX_HOSTNAME: kafka
      KAFKA_OPTS: -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.local.only=false -Djava.rmi.server.hostname=kafka -Dcom.sun.management.jmxremote.rmi.port=9999
    volumes:
      - kafka-data:/var/lib/kafka/data
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 10s
      timeout: 10s
      retries: 10
    networks:
      - log-beaver

  kafka-connect:
    build:
      context: .
      dockerfile: kafka/kafka-connect/Dockerfile
    depends_on:
      kafka:
        condition: service_healthy
    ports:
      - "8083:8083"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: kafka:9092
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: connect-cluster
      CONNECT_CONFIG_STORAGE_TOPIC: connect-configs
      CONNECT_OFFSET_STORAGE_TOPIC: connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: connect-status
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE: "false"
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: "false"
      CONNECT_INTERNAL_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_PLUGIN_PATH: /usr/share/java,/usr/share/confluent-hub-components,/usr/share/java/clickhouse-kafka-connect
      CONNECT_REST_ADVERTISED_HOST_NAME: kafka-connect
      CONNECT_LOG4J_ROOT_LOGLEVEL: INFO
      KAFKA_HEAP_OPTS: ${CONNECT_HEAP_OPTS:-"-Xms512M -Xmx2G"}
      KAFKA_JMX_PORT: 9998
      KAFKA_JMX_HOSTNAME: kafka-connect
      KAFKA_OPTS: -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.local.only=false -Djava.rmi.server.hostname=kafka-connect -Dcom.sun.management.jmxremote.rmi.port=9998
    volumes:
      - connect-data:/var/lib/kafka-connect
      - ./kafka/connectors:/etc/kafka-connect/connectors
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8083/connectors"]
      interval: 10s
      timeout: 10s
      retries: 10
    networks:
      - log-beaver

  clickhouse:
    image: clickhouse/clickhouse-server:23.8
    env_file:
      - .env
    environment:
      CLICKHOUSE_DB: ${CLICKHOUSE_DB:-log_beaver}
      CLICKHOUSE_USER: ${CLICKHOUSE_USER:-log_beaver}
      CLICKHOUSE_PASSWORD: ${CLICKHOUSE_PASSWORD:-log_beaver}
    ports:
      - "8123:8123"
      - "9000:9000"
      - "9363:9363"
    volumes:
      - clickhouse-data:/var/lib/clickhouse
      - clickhouse-logs:/var/log/clickhouse-server
      - ./clickhouse/config.d:/etc/clickhouse-server/config.d
      - ./clickhouse/initdb.d:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD", "bash", "-c", "clickhouse-client --query 'SELECT 1'"]
      interval: 10s
      timeout: 5s
      retries: 10
    networks:
      - log-beaver

  airflow-db:
    image: postgres:14-alpine
    env_file:
      - .env
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: ${AIRFLOW_DB_PASSWORD:-airflow}
      POSTGRES_DB: airflow
    ports:
      - "5433:5432"
    volumes:
      - airflow-db-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow"]
      interval: 10s
      timeout: 5s
      retries: 10
    networks:
      - log-beaver

  airflow-init:
    <<: *airflow-common
    entrypoint: /bin/bash
    command:
      - -c
      - |
        airflow db migrate && \
        airflow users create \
          --role Admin \
          --username "${AIRFLOW_USERNAME:-admin}" \
          --password "${AIRFLOW_PASSWORD:-admin}" \
          --firstname Airflow \
          --lastname Admin \
          --email "${AIRFLOW_EMAIL:-admin@example.com}" || true
    restart: "no"

  airflow-scheduler:
    <<: *airflow-common
    command: ["airflow", "scheduler"]
    environment:
      <<: *airflow-common-env
      AIRFLOW__INTERNAL_API__BASE_URL: http://airflow-webserver:8080
      AIRFLOW__INTERNAL_API__AUTH_BACKENDS: airflow.api.auth.backend.default
    depends_on:
      airflow-db:
        condition: service_healthy
      airflow-init:
        condition: service_completed_successfully

  airflow-webserver:
    <<: *airflow-common
    command: ["airflow", "api-server"]
    environment:
      <<: *airflow-common-env
      AIRFLOW__INTERNAL_API__BASE_URL: http://airflow-webserver:8080
      AIRFLOW__INTERNAL_API__AUTH_BACKENDS: airflow.api.auth.backend.default
    depends_on:
      airflow-db:
        condition: service_healthy
      airflow-init:
        condition: service_completed_successfully
    ports:
      - "8080:8080"

  kafka-jmx-exporter:
    image: bitnami/jmx-exporter:latest
    command: ["5556", "/etc/jmx-exporter/config.yml"]
    depends_on:
      kafka:
        condition: service_healthy
    volumes:
      - ./monitoring/jmx/kafka.yml:/etc/jmx-exporter/config.yml:ro
    ports:
      - "5556:5556"
    networks:
      - log-beaver

  kafka-connect-jmx-exporter:
    image: bitnami/jmx-exporter:latest
    command: ["5557", "/etc/jmx-exporter/config.yml"]
    depends_on:
      kafka-connect:
        condition: service_healthy
    volumes:
      - ./monitoring/jmx/kafka-connect.yml:/etc/jmx-exporter/config.yml:ro
    ports:
      - "5557:5557"
    networks:
      - log-beaver

  prometheus:
    image: prom/prometheus:v2.55.1
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    extra_hosts:
      - "host.docker.internal:host-gateway"
    ports:
      - "9090:9090"
    depends_on:
      kafka-jmx-exporter:
        condition: service_started
      kafka-connect-jmx-exporter:
        condition: service_started
      clickhouse:
        condition: service_healthy
    networks:
      - log-beaver

  grafana:
    image: grafana/grafana:11.2.0
    environment:
      GF_SECURITY_ADMIN_USER: ${GRAFANA_ADMIN_USER:-admin}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD:-admin}
      GF_USERS_DEFAULT_THEME: light
    volumes:
      - grafana-data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards:ro
    ports:
      - "3000:3000"
    depends_on:
      prometheus:
        condition: service_started
    networks:
      - log-beaver

networks:
  log-beaver:
    driver: bridge

volumes:
  zookeeper-data:
  zookeeper-log:
  kafka-data:
  connect-data:
  clickhouse-data:
  clickhouse-logs:
  airflow-db-data:
  prometheus-data:
  grafana-data:
